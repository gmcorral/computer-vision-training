{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker Mxnet/gluon Example\n",
    "Let's use the final project dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.mxnet import MXNet\n",
    "from mxnet import gluon\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the dataset from our s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                data  label\n",
      "0  [[[255, 255, 255], [255, 255, 255], [255, 255,...      4\n",
      "1  [[[255, 255, 255], [255, 255, 255], [255, 255,...      1\n",
      "2  [[[255, 255, 255], [255, 255, 255], [255, 255,...      4\n",
      "3  [[[255, 255, 255], [255, 255, 255], [255, 255,...      3\n",
      "4  [[[255, 255, 255], [255, 255, 255], [255, 255,...      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "sm = boto3.client('s3')\n",
    "response = sm.get_object(Bucket='amazon-ml-accelerator', Key='mla-cv-sagemaker-demo/training_data.pkl')\n",
    "model_str = response['Body'].read()\n",
    "df = pickle.loads(model_str)\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing the data for xnet/gluon format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "\n",
    "image_vals = df[\"data\"].values\n",
    "label_vals = df[\"label\"].values\n",
    "\n",
    "del df\n",
    "\n",
    "# Create image and label arrays\n",
    "images = np.zeros((image_vals.shape[0], 3, 224, 224))\n",
    "labels = np.zeros((label_vals.shape[0]))\n",
    "\n",
    "# Iterate through the dataframe row by row\n",
    "for i, (im, label) in enumerate(zip(image_vals, label_vals)):\n",
    "    # Get image from the data column of the current row\n",
    "    \n",
    "    # We need a fixed size input, our images have different sizes, let's pick 224x224.\n",
    "    # Resize image below\n",
    "    im = resize(im, output_shape=(224, 224))\n",
    "    \n",
    "    # Gluon/mxnet expects images in this format (channel, row, column)\n",
    "    # This is the opposite of (row, column, channel), let's fix it\n",
    "    im = np.moveaxis(im, -1, 0)\n",
    "    \n",
    "    # Assign the value in the image array\n",
    "    images[i] = im\n",
    "    \n",
    "    # Assign the label in the label array\n",
    "    labels[i] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data into Training, Validation, Test and saving into s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, stratify=labels, test_size=0.20)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, stratify=y_test, test_size=0.5)\n",
    "\n",
    "# Save training and validation data locally\n",
    "np.save('train_data', X_train)\n",
    "np.save('train_label', y_train)\n",
    "np.save('validation_data', X_val)\n",
    "np.save('validation_label', y_val)\n",
    "np.save('test_data', X_test)\n",
    "np.save('test_label', y_test)\n",
    "\n",
    "prefix = 'mla-cv-sagemaker-demo'\n",
    "bucket = 'amazon-ml-accelerator'\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'training/train_data.npy')).upload_file('train_data.npy')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'training/train_label.npy')).upload_file('train_label.npy')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation_data.npy')).upload_file('validation_data.npy')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation_label.npy')).upload_file('validation_label.npy')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'test/test_data.npy')).upload_file('test_data.npy')\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'test/test_label.npy')).upload_file('test_label.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's clear the files we saved locally (they are already uploaded to s3 above)\n",
    "! rm train_data.npy train_label.npy validation_data.npy validation_label.npy test_data.npy test_label.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = 's3://{}/{}'.format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MXNet(\"final_project.py\",\n",
    "          role=role,\n",
    "          train_instance_count=1,\n",
    "          train_instance_type=\"ml.p2.xlarge\",\n",
    "          framework_version=\"1.2.1\",\n",
    "          py_version = 'py3',\n",
    "          hyperparameters={'batch_size': 32,\n",
    "                           'epochs': 20,\n",
    "                           'learning_rate': 0.01,\n",
    "                           'patience': 5\n",
    "                          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-18 20:25:04 Starting - Starting the training job...\n",
      "2019-10-18 20:25:05 Starting - Launching requested ML instances......\n",
      "2019-10-18 20:26:32 Starting - Preparing the instances for training.........\n",
      "2019-10-18 20:27:41 Downloading - Downloading input data.........\n",
      "2019-10-18 20:29:29 Training - Downloading the training image...\n",
      "2019-10-18 20:29:49 Training - Training image download completed. Training in progress.\u001b[31m2019-10-18 20:29:49,337 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[31m2019-10-18 20:29:49,338 INFO - root - starting train task\u001b[0m\n",
      "\u001b[31m2019-10-18 20:29:49,360 INFO - container_support.training - Training starting\u001b[0m\n",
      "\u001b[31m2019-10-18 20:29:50,738 WARNING - mxnet_container.train - #033[1;33mThis required structure for training scripts will be deprecated with the next major release of MXNet images. The train() function will no longer be required; instead the training script must be able to be run as a standalone script. For more information, see https://github.com/aws/sagemaker-python-sdk/tree/master/src/sagemaker/mxnet#updating-your-mxnet-training-script.#033[1;0m\u001b[0m\n",
      "\u001b[31m2019-10-18 20:29:50,752 INFO - mxnet_container.train - MXNetTrainingEnvironment: {'model_dir': '/opt/ml/model', 'resource_config': {'network_interface_name': 'eth0', 'current_host': 'algo-1', 'hosts': ['algo-1']}, '_ps_verbose': 0, '_scheduler_host': 'algo-1', 'code_dir': '/opt/ml/code', 'user_script_name': 'final_project.py', 'hyperparameters': {'sagemaker_enable_cloudwatch_metrics': False, 'patience': 5, 'sagemaker_job_name': 'sagemaker-mxnet-2019-10-18-20-25-03-160', 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.01, 'sagemaker_submit_directory': 's3://sagemaker-us-west-2-809085364189/sagemaker-mxnet-2019-10-18-20-25-03-160/source/sourcedir.tar.gz', 'sagemaker_program': 'final_project.py', 'sagemaker_region': 'us-west-2', 'sagemaker_container_log_level': 20}, 'base_dir': '/opt/ml', 'input_dir': '/opt/ml/input', 'available_cpus': 4, 'available_gpus': 1, 'hosts': ['algo-1'], 'channel_dirs': {'training': '/opt/ml/input/data/training'}, 'user_requirements_file': None, 'sagemaker_region': 'us-west-2', 'output_data_dir': '/opt/ml/output/data/', '_ps_port': 8000, 'current_host': 'algo-1', 'channels': {'training': {'TrainingInputMode': 'File', 'S3DistributionType': 'FullyReplicated', 'RecordWrapperType': 'None'}}, 'user_script_archive': 's3://sagemaker-us-west-2-809085364189/sagemaker-mxnet-2019-10-18-20-25-03-160/source/sourcedir.tar.gz', 'enable_cloudwatch_metrics': False, 'input_config_dir': '/opt/ml/input/config', 'job_name': 'sagemaker-mxnet-2019-10-18-20-25-03-160', 'output_dir': '/opt/ml/output', '_scheduler_ip': '10.0.154.122', 'container_log_level': 20}\u001b[0m\n",
      "\u001b[31mDownloading s3://sagemaker-us-west-2-809085364189/sagemaker-mxnet-2019-10-18-20-25-03-160/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[31m2019-10-18 20:29:51,005 INFO - mxnet_container.train - Starting distributed training task\u001b[0m\n",
      "\u001b[31m/usr/local/lib/python3.5/dist-packages/mxnet_container/train.py:190: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  train_args = inspect.getargspec(user_module.train)\u001b[0m\n",
      "\u001b[31m(1436, 3, 224, 224)\u001b[0m\n",
      "\u001b[31m(1436,)\u001b[0m\n",
      "\u001b[31m(180, 3, 224, 224)\u001b[0m\n",
      "\u001b[31m(180,)\u001b[0m\n",
      "\u001b[31m[20:30:11] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:107: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[31m[Epoch 0] Training: accuracy=0.379526 loss: 1.312451\u001b[0m\n",
      "\u001b[31m[Epoch 0] Validation: accuracy=0.405556 loss: 1.268821\u001b[0m\n",
      "\u001b[31m[Epoch 1] Training: accuracy=0.410167 loss: 1.253637\u001b[0m\n",
      "\u001b[31m[Epoch 1] Validation: accuracy=0.405556 loss: 1.252119\u001b[0m\n",
      "\u001b[31m[Epoch 2] Training: accuracy=0.427577 loss: 1.218503\u001b[0m\n",
      "\u001b[31m[Epoch 2] Validation: accuracy=0.405556 loss: 1.215619\u001b[0m\n",
      "\u001b[31m[Epoch 3] Training: accuracy=0.444986 loss: 1.183898\u001b[0m\n",
      "\u001b[31m[Epoch 3] Validation: accuracy=0.411111 loss: 1.181860\u001b[0m\n",
      "\u001b[31m[Epoch 4] Training: accuracy=0.463092 loss: 1.146714\u001b[0m\n",
      "\u001b[31m[Epoch 4] Validation: accuracy=0.411111 loss: 1.165529\u001b[0m\n",
      "\u001b[31m[Epoch 5] Training: accuracy=0.492340 loss: 1.112424\u001b[0m\n",
      "\u001b[31m[Epoch 5] Validation: accuracy=0.416667 loss: 1.122705\u001b[0m\n",
      "\u001b[31m[Epoch 6] Training: accuracy=0.520891 loss: 1.069293\u001b[0m\n",
      "\u001b[31m[Epoch 6] Validation: accuracy=0.427778 loss: 1.093803\u001b[0m\n",
      "\u001b[31m[Epoch 7] Training: accuracy=0.550836 loss: 1.025503\u001b[0m\n",
      "\u001b[31m[Epoch 7] Validation: accuracy=0.461111 loss: 1.045212\u001b[0m\n",
      "\u001b[31m[Epoch 8] Training: accuracy=0.578691 loss: 0.974419\u001b[0m\n",
      "\u001b[31m[Epoch 8] Validation: accuracy=0.477778 loss: 1.012727\u001b[0m\n",
      "\u001b[31m[Epoch 9] Training: accuracy=0.603760 loss: 0.922692\u001b[0m\n",
      "\u001b[31m[Epoch 9] Validation: accuracy=0.511111 loss: 0.987803\u001b[0m\n",
      "\u001b[31m[Epoch 10] Training: accuracy=0.630919 loss: 0.866411\u001b[0m\n",
      "\u001b[31m[Epoch 10] Validation: accuracy=0.572222 loss: 0.949363\u001b[0m\n",
      "\u001b[31m[Epoch 11] Training: accuracy=0.683148 loss: 0.807096\u001b[0m\n",
      "\u001b[31m[Epoch 11] Validation: accuracy=0.511111 loss: 0.977547\u001b[0m\n",
      "\u001b[31m[Epoch 12] Training: accuracy=0.707521 loss: 0.747286\u001b[0m\n",
      "\u001b[31m[Epoch 12] Validation: accuracy=0.627778 loss: 0.872321\u001b[0m\n",
      "\u001b[31m[Epoch 13] Training: accuracy=0.751393 loss: 0.670154\u001b[0m\n",
      "\u001b[31m[Epoch 13] Validation: accuracy=0.655556 loss: 0.865001\u001b[0m\n",
      "\u001b[31m[Epoch 14] Training: accuracy=0.767409 loss: 0.606847\u001b[0m\n",
      "\u001b[31m[Epoch 14] Validation: accuracy=0.666667 loss: 0.831371\u001b[0m\n",
      "\u001b[31m[Epoch 15] Training: accuracy=0.811978 loss: 0.521578\u001b[0m\n",
      "\u001b[31m[Epoch 15] Validation: accuracy=0.666667 loss: 0.859987\u001b[0m\n",
      "\n",
      "2019-10-18 20:31:36 Uploading - Uploading generated training model\u001b[31m[Epoch 16] Training: accuracy=0.849582 loss: 0.438724\u001b[0m\n",
      "\u001b[31m[Epoch 16] Validation: accuracy=0.700000 loss: 0.805147\u001b[0m\n",
      "\u001b[31m[Epoch 17] Training: accuracy=0.872563 loss: 0.405904\u001b[0m\n",
      "\u001b[31m[Epoch 17] Validation: accuracy=0.700000 loss: 0.845234\u001b[0m\n",
      "\u001b[31m[Epoch 18] Training: accuracy=0.900418 loss: 0.316810\u001b[0m\n",
      "\u001b[31m[Epoch 18] Validation: accuracy=0.666667 loss: 0.916623\u001b[0m\n",
      "\u001b[31m[Epoch 19] Training: accuracy=0.907382 loss: 0.288710\u001b[0m\n",
      "\u001b[31m[Epoch 19] Validation: accuracy=0.727778 loss: 0.844057\u001b[0m\n",
      "\n",
      "2019-10-18 20:31:51 Completed - Training job completed\n",
      "Training seconds: 250\n",
      "Billable seconds: 250\n"
     ]
    }
   ],
   "source": [
    "m.fit(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: sagemaker-mxnet-2019-10-18-20-25-03-160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor = m.deploy(instance_type='ml.m4.xlarge', initial_instance_count=1, endpoint_name='mla-cv-endpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's test this endpoint\n",
    "We will read the test data from our S3 buckets and call the endpoint we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from io import BytesIO\n",
    "import mxnet.ndarray as nd\n",
    "import boto3\n",
    "\n",
    "sm = boto3.client('s3')\n",
    "obj = sm.get_object(Bucket='amazon-ml-accelerator', Key='mla-cv-sagemaker-demo/test/test_data.npy')\n",
    "X_test = np.load(BytesIO(obj['Body'].read()))\n",
    "\n",
    "obj = sm.get_object(Bucket='amazon-ml-accelerator', Key='mla-cv-sagemaker-demo/test/test_label.npy')\n",
    "y_test = np.load(BytesIO(obj['Body'].read()))\n",
    "\n",
    "payload = X_test[:4]\n",
    "payload = bytearray(payload)\n",
    "\n",
    "runtime = boto3.Session().client(service_name='runtime.sagemaker')\n",
    "response = runtime.invoke_endpoint(EndpointName=\"mla-cv-endpoint\", \n",
    "                                   ContentType='application/x-image', \n",
    "                                   Body=payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'[2.0, 1.0, 1.0, 4.0]'\n"
     ]
    }
   ],
   "source": [
    "print(response['Body'].read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
